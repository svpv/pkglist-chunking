#!/bin/sh -efu
#
# The seed used during compression may be different from the seed
# used at dictionary creation time (resulting in different chunking).
# This program tests whether using the same seed improves compression
# (the answer is no).

level=-19
dopt='-d6 -k600'
iter=${1:-10}

Job()
{
    seed=$(od -An -v -tx8 -N8 </dev/urandom)
    seed=0x${seed# }

    job=$1 arch=$2
    xz -d <data/01-$arch-srclist.classic.xz |
    ./train-srclist $dopt $level --seed=$seed >tmp/dict$job

    # Compress with the same chunking as dict.
    s1=$(xz -d <data/01-$arch-srclist.classic.xz |
	./compress-srclist -D tmp/dict$job $level --seed=$seed 2>/dev/null |wc -c)

    seed=$(od -An -v -tx8 -N8 </dev/urandom)
    seed=0x${seed# }

    # Compress with another seed, chunked differently.
    s2=$(xz -d <data/01-$arch-srclist.classic.xz |
	./compress-srclist -D tmp/dict$job $level --seed=$seed 2>/dev/null |wc -c)

    printf '%s\t%s\n' $s1 $s2
}

Stats()
{
    perl -MStatistics::Descriptive -lne '
	BEGIN { $S = Statistics::Descriptive::Full->new; }
	$S->add_data($_);
	END { printf "%dÂ±%d\n", $S->mean, $S->standard_deviation; }
    '
}

for arch in x86_64 noarch; do
    for i in `seq 1 $iter`; do
	Job 1 $arch &
	Job 2 $arch
	wait $!
    done >tmp/sizes.$arch
    echo $arch $(cut -f1 tmp/sizes.$arch |Stats) \
	       $(cut -f2 tmp/sizes.$arch |Stats)
done
